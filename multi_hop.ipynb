{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Generalizing Optimal Arbitrage to N-Hop Paths via Möbius Transformations\n",
    "\n",
    "This notebook generalizes the closed-form arbitrage formula from the [original single-hop analysis](https://medium.com/@jeffreyhartigan/deriving-a-closed-form-solution-for-optimal-dex-arbitrage-b7c917bbe3e7) to arbitrary multi-hop paths across constant product AMMs. The key insight: each AMM swap is a **Möbius transformation**, and Möbius transformations compose via matrix multiplication. This means the entire n-hop path collapses to a single fractional-linear function, preserving the closed-form structure regardless of path length.\n",
    "\n",
    "The result is a general formula that computes the profit-maximizing trade size for any n-hop circular arbitrage in $O(n)$ time with **zero iteration** — extending the original $O(1)$ two-pool formula to paths of arbitrary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:43.723206Z",
     "iopub.status.busy": "2026-02-22T05:10:43.723015Z",
     "iopub.status.idle": "2026-02-22T05:10:43.799606Z",
     "shell.execute_reply": "2026-02-22T05:10:43.799104Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-recap",
   "metadata": {},
   "source": [
    "## Recap: Single-Hop Closed Form\n",
    "\n",
    "In the [original analysis](optimal_arbitrage.ipynb), we derived the profit-maximizing input for a two-pool arbitrage. Starting from the constant product equations with fee factor $k$:\n",
    "\n",
    "$$y = b - \\frac{ab}{a + kx}, \\quad z = c - \\frac{cd}{d + ky}$$\n",
    "\n",
    "We found that setting $\\frac{dz}{dx} = 1$ and solving for $x$ yields:\n",
    "\n",
    "$$x_{\\text{ideal}} = \\frac{k\\sqrt{abcd} - ad}{k(bk + d)}$$\n",
    "\n",
    "where $(a, b)$ and $(c, d)$ are pool reserves and $k = 0.997$ is the fee factor. This is an exact $O(1)$ result — no iteration, no approximation.\n",
    "\n",
    "**The question: can this be generalized to n hops?**\n",
    "\n",
    "The original writeup noted that multi-hop paths produce \"higher-degree polynomials under the square root\" and \"may not admit clean closed-form solutions.\" It turns out this concern was unfounded. The algebra has hidden structure that keeps the solution clean for any number of hops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-mobius",
   "metadata": {},
   "source": [
    "## The Key Insight: AMM Swaps as Möbius Transformations\n",
    "\n",
    "A single constant product swap with input reserve $r$, output reserve $s$, and fee factor $f$ produces:\n",
    "\n",
    "$$\\text{output} = \\frac{s \\cdot f \\cdot \\text{input}}{r + f \\cdot \\text{input}}$$\n",
    "\n",
    "This is algebraically equivalent to the formula $y = b - \\frac{ab}{a + kx}$ from the original derivation:\n",
    "\n",
    "$$y = b - \\frac{ab}{a + kx} = \\frac{b(a + kx) - ab}{a + kx} = \\frac{bkx}{a + kx}$$\n",
    "\n",
    "This function has the form $\\frac{\\alpha x}{\\beta + \\gamma x}$, which is a **Möbius transformation** (also called a linear fractional transformation) — specifically one that maps $0 \\to 0$.\n",
    "\n",
    "Möbius transformations have a remarkable algebraic property: **the composition of any two Möbius transformations is again a Möbius transformation.** Furthermore, because every AMM swap sends $0 \\to 0$ (zero input always gives zero output), the composed function after any number of hops retains this special form:\n",
    "\n",
    "$$l(x) = \\frac{Kx}{M + Nx}$$\n",
    "\n",
    "where $K$, $M$, $N$ are constants determined solely by the pool reserves and fees along the path. No matter how many hops — 2, 5, 50 — the output function always has this same simple structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-matrix",
   "metadata": {},
   "source": [
    "## Matrix Representation\n",
    "\n",
    "Each hop can be encoded as a $2 \\times 2$ matrix. The Möbius transformation $f(x) = \\frac{sf \\cdot x}{r + f \\cdot x}$ corresponds to:\n",
    "\n",
    "$$\\mathbf{M}_i = \\begin{pmatrix} s_i f_i & 0 \\\\ f_i & r_i \\end{pmatrix}$$\n",
    "\n",
    "The matrix acts on $x$ via the rule: if $\\mathbf{M} = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$, then $f(x) = \\frac{ax + b}{cx + d}$.\n",
    "\n",
    "Composing $n$ hops is simply **matrix multiplication** (applied right-to-left, matching function composition order):\n",
    "\n",
    "$$\\mathbf{M}_{\\text{total}} = \\mathbf{M}_n \\cdot \\mathbf{M}_{n-1} \\cdots \\mathbf{M}_2 \\cdot \\mathbf{M}_1 = \\begin{pmatrix} K & 0 \\\\ N & M \\end{pmatrix}$$\n",
    "\n",
    "The top-right entry remains exactly zero throughout the multiplication — a consequence of every individual map fixing the origin ($0 \\to 0$).\n",
    "\n",
    "The composed output is then:\n",
    "\n",
    "$$l(x) = \\frac{Kx}{M + Nx}$$\n",
    "\n",
    "This is the entire multi-hop transfer function encoded in three numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-recurrence",
   "metadata": {},
   "source": [
    "## The 3-Number Recurrence\n",
    "\n",
    "The matrix product can be computed without storing full matrices. We maintain just three scalars $K$, $M$, $N$ and update them one hop at a time.\n",
    "\n",
    "**Initialize** with the first hop (input reserve $r_1$, output reserve $s_1$, fee $f_1$):\n",
    "\n",
    "$$K = s_1 f_1, \\quad M = r_1, \\quad N = f_1$$\n",
    "\n",
    "**Update** for each subsequent hop $i$ with reserves $(r_i, s_i)$ and fee $f_i$:\n",
    "\n",
    "$$K_{\\text{new}} = s_i \\cdot f_i \\cdot K$$\n",
    "\n",
    "$$M_{\\text{new}} = r_i \\cdot M$$\n",
    "\n",
    "$$N_{\\text{new}} = r_i \\cdot N + f_i \\cdot K$$\n",
    "\n",
    "**Important:** the update for $N$ uses the value of $K$ **before** it is updated in this step. In code, all three values are computed from the old state before any are overwritten.\n",
    "\n",
    "After processing all $n$ hops, we have the final $K$, $M$, $N$ and the composed transfer function $l(x) = \\frac{Kx}{M + Nx}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-derivative",
   "metadata": {},
   "source": [
    "## General Derivative and Optimal Arbitrage\n",
    "\n",
    "With $l(x) = \\frac{Kx}{M + Nx}$, the derivative is straightforward:\n",
    "\n",
    "$$\\frac{dl}{dx} = \\frac{K(M + Nx) - Kx \\cdot N}{(M + Nx)^2} = \\frac{KM}{(M + Nx)^2}$$\n",
    "\n",
    "The profit function is $\\text{profit}(x) = l(x) - x$, so the optimality condition is:\n",
    "\n",
    "$$\\frac{d}{dx}\\text{profit}(x) = \\frac{dl}{dx} - 1 = 0$$\n",
    "\n",
    "$$\\frac{KM}{(M + Nx)^2} = 1$$\n",
    "\n",
    "$$(M + Nx)^2 = KM$$\n",
    "\n",
    "$$M + Nx = \\sqrt{KM} \\quad \\text{(positive root)}$$\n",
    "\n",
    "$$\\boxed{x_{\\text{opt}} = \\frac{\\sqrt{KM} - M}{N}}$$\n",
    "\n",
    "This formula works for **any number of hops**. Profitable arbitrage exists when $\\frac{K}{M} > 1$ (the initial marginal exchange rate exceeds unity).\n",
    "\n",
    "**Complexity:** $O(n)$ to compute $K, M, N$ via the recurrence (one pass through the pools), then $O(1)$ for the square root formula. The total is $O(n)$ — linear in the number of hops, with no iteration or numerical solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-impl",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:43.801440Z",
     "iopub.status.busy": "2026-02-22T05:10:43.801310Z",
     "iopub.status.idle": "2026-02-22T05:10:43.804729Z",
     "shell.execute_reply": "2026-02-22T05:10:43.804398Z"
    }
   },
   "outputs": [],
   "source": [
    "def compose_amm_chain(pools):\n",
    "    \"\"\"\n",
    "    Compute K, M, N for a multi-hop AMM path using the 3-number recurrence.\n",
    "\n",
    "    Parameters:\n",
    "        pools: list of tuples (r_in, s_out, fee_factor)\n",
    "               Each tuple represents one hop in the path.\n",
    "\n",
    "    Returns:\n",
    "        K, M, N such that the composed output is l(x) = Kx / (M + Nx)\n",
    "    \"\"\"\n",
    "    r, s, f = pools[0]\n",
    "    K = s * f\n",
    "    M = r\n",
    "    N = f\n",
    "\n",
    "    for r, s, f in pools[1:]:\n",
    "        K_new = s * f * K\n",
    "        M_new = r * M\n",
    "        N_new = r * N + f * K  # uses K before update\n",
    "        K, M, N = K_new, M_new, N_new\n",
    "\n",
    "    return K, M, N\n",
    "\n",
    "\n",
    "def optimal_arbitrage_multihop(pools):\n",
    "    \"\"\"\n",
    "    Compute the profit-maximizing input for an n-hop arbitrage path.\n",
    "\n",
    "    Parameters:\n",
    "        pools: list of tuples (r_in, s_out, fee_factor)\n",
    "\n",
    "    Returns:\n",
    "        x_opt: optimal input amount (0 if no profitable arbitrage)\n",
    "        profit: expected profit at x_opt\n",
    "    \"\"\"\n",
    "    K, M, N = compose_amm_chain(pools)\n",
    "\n",
    "    # No arbitrage if initial marginal rate <= 1\n",
    "    if K <= M:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    x_opt = (sqrt(K * M) - M) / N\n",
    "\n",
    "    # Compute actual profit: l(x_opt) - x_opt\n",
    "    l_x = K * x_opt / (M + N * x_opt)\n",
    "    profit = l_x - x_opt\n",
    "\n",
    "    return x_opt, profit\n",
    "\n",
    "\n",
    "def simulate_multihop(x, pools):\n",
    "    \"\"\"Simulate the actual output of sending x through the multi-hop path.\"\"\"\n",
    "    amount = x\n",
    "    for r, s, f in pools:\n",
    "        amount = (s * f * amount) / (r + f * amount)\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-verify-header",
   "metadata": {},
   "source": [
    "## Verification: 2-Hop Case Matches the Original Formula\n",
    "\n",
    "Using the same SHIB/ETH pool data from the original analysis, the multi-hop recurrence should produce identical results to the single-hop formula $x_{\\text{ideal}} = \\frac{k\\sqrt{abcd} - ad}{k(bk + d)}$.\n",
    "\n",
    "To map the 2-pool setup into the multi-hop framework:\n",
    "- **Hop 1:** Input token₀ into Pool A. Input reserve = $a$ (token₀), output reserve = $b$ (token₁), fee = $k$.\n",
    "- **Hop 2:** Input token₁ into Pool B. Input reserve = $d$ (token₁), output reserve = $c$ (token₀), fee = $k$.\n",
    "\n",
    "The recurrence gives:\n",
    "- After hop 1: $K = bk$, $M = a$, $N = k$\n",
    "- After hop 2: $K = bck^2$, $M = ad$, $N = k(bk + d)$\n",
    "\n",
    "Plugging into $x_{\\text{opt}} = \\frac{\\sqrt{KM} - M}{N}$:\n",
    "\n",
    "$$x_{\\text{opt}} = \\frac{\\sqrt{bck^2 \\cdot ad} - ad}{k(bk + d)} = \\frac{k\\sqrt{abcd} - ad}{k(bk + d)}$$\n",
    "\n",
    "This is **exactly** the original formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-verify-code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:43.806164Z",
     "iopub.status.busy": "2026-02-22T05:10:43.806076Z",
     "iopub.status.idle": "2026-02-22T05:10:43.809477Z",
     "shell.execute_reply": "2026-02-22T05:10:43.809005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Hop Verification Against Original Formula\n",
      "==================================================\n",
      "Original formula:     x = 7.9210884160\n",
      "Multi-hop recurrence: x = 7.9210884160\n",
      "Difference:               8.88e-16\n",
      "\n",
      "Profit (analytic):        0.0159546619\n",
      "Simulated output:         7.9370430779\n",
      "Simulated profit:         0.0159546619\n",
      "Profit match:             True\n"
     ]
    }
   ],
   "source": [
    "# Original pool data from the single-hop analysis (SHIB/ETH on Uniswap V2)\n",
    "a = 15800.025178893529930149   # Token0 in Pool A\n",
    "b = 30348149.556699            # Token1 in Pool A\n",
    "c = 5251.705779226172996106    # Token0 in Pool B\n",
    "d = 9986593.845926             # Token1 in Pool B\n",
    "k = 0.997                     # Fee factor (0.3% fee)\n",
    "\n",
    "# Original closed-form formula (single-hop specific)\n",
    "x_original = (k * sqrt(a * b * c * d) - a * d) / (k * (b * k + d))\n",
    "\n",
    "# Multi-hop recurrence with 2 pools\n",
    "# Hop 1: token0 -> token1 via Pool A  (r=a, s=b, f=k)\n",
    "# Hop 2: token1 -> token0 via Pool B  (r=d, s=c, f=k)\n",
    "pools_2hop = [(a, b, k), (d, c, k)]\n",
    "x_multihop, profit_multihop = optimal_arbitrage_multihop(pools_2hop)\n",
    "\n",
    "# Compare\n",
    "print(\"2-Hop Verification Against Original Formula\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original formula:     x = {x_original:.10f}\")\n",
    "print(f\"Multi-hop recurrence: x = {x_multihop:.10f}\")\n",
    "print(f\"Difference:               {abs(x_original - x_multihop):.2e}\")\n",
    "print(f\"\\nProfit (analytic):        {profit_multihop:.10f}\")\n",
    "\n",
    "# Cross-check via simulation\n",
    "actual_output = simulate_multihop(x_multihop, pools_2hop)\n",
    "print(f\"Simulated output:         {actual_output:.10f}\")\n",
    "print(f\"Simulated profit:         {actual_output - x_multihop:.10f}\")\n",
    "print(f\"Profit match:             {abs(profit_multihop - (actual_output - x_multihop)) < 1e-10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-multihop-header",
   "metadata": {},
   "source": [
    "## Multi-Hop Arbitrage: 3, 4, and 5 Hop Paths\n",
    "\n",
    "To validate the general formula beyond the 2-hop case, we construct synthetic multi-hop circular arbitrage paths. Each path represents a round-trip trade (e.g., Token A $\\to$ B $\\to$ C $\\to$ A) where price discrepancies across pools create a profitable cycle.\n",
    "\n",
    "For each path, we verify that:\n",
    "1. The closed-form $x_{\\text{opt}} = \\frac{\\sqrt{KM} - M}{N}$ produces a valid result\n",
    "2. The analytic profit matches the simulated profit (feeding $x_{\\text{opt}}$ through the actual swap chain)\n",
    "3. The initial marginal rate $K/M > 1$ (confirming arbitrage exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-multihop-data",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:43.810763Z",
     "iopub.status.busy": "2026-02-22T05:10:43.810664Z",
     "iopub.status.idle": "2026-02-22T05:10:43.814253Z",
     "shell.execute_reply": "2026-02-22T05:10:43.813763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3-hop path:\n",
      "  K/M (initial marginal rate): 1.120700\n",
      "  x_opt:                       19.078671\n",
      "  Analytic profit:             1.118604\n",
      "  Simulated profit:            1.118604\n",
      "  Match:                       True\n",
      "\n",
      "4-hop path:\n",
      "  K/M (initial marginal rate): 1.147772\n",
      "  x_opt:                       85.827103\n",
      "  Analytic profit:             6.123027\n",
      "  Simulated profit:            6.123027\n",
      "  Match:                       True\n",
      "\n",
      "5-hop path:\n",
      "  K/M (initial marginal rate): 1.178442\n",
      "  x_opt:                       162.151803\n",
      "  Analytic profit:             13.873792\n",
      "  Simulated profit:            13.873792\n",
      "  Match:                       True\n"
     ]
    }
   ],
   "source": [
    "# 3-hop path: Token A -> Token B -> Token C -> Token A\n",
    "# Reserves chosen to create a small round-trip price edge\n",
    "pools_3hop = [\n",
    "    (1000.0, 2050000.0, 0.997),    # Pool 1: A/B  (r_in=A, s_out=B)\n",
    "    (2000000.0, 1020.0, 0.997),    # Pool 2: B/C  (r_in=B, s_out=C)\n",
    "    (980.0, 1060.0, 0.997),        # Pool 3: C/A  (r_in=C, s_out=A)\n",
    "]\n",
    "\n",
    "# 4-hop path: Token A -> B -> C -> D -> A\n",
    "pools_4hop = [\n",
    "    (5000.0, 10200000.0, 0.997),   # Pool 1: A/B\n",
    "    (10000000.0, 5100.0, 0.997),   # Pool 2: B/C\n",
    "    (4900.0, 9900000.0, 0.997),    # Pool 3: C/D\n",
    "    (9500000.0, 5250.0, 0.997),    # Pool 4: D/A\n",
    "]\n",
    "\n",
    "# 5-hop path: Token A -> B -> C -> D -> E -> A\n",
    "pools_5hop = [\n",
    "    (10000.0, 20500000.0, 0.997),  # Pool 1: A/B\n",
    "    (20000000.0, 10200.0, 0.997),  # Pool 2: B/C\n",
    "    (9800.0, 20000000.0, 0.997),   # Pool 3: C/D\n",
    "    (19500000.0, 10100.0, 0.997),  # Pool 4: D/E\n",
    "    (9700.0, 10500.0, 0.997),      # Pool 5: E/A\n",
    "]\n",
    "\n",
    "# Compute and verify for each path length\n",
    "for name, pools in [(\"3-hop\", pools_3hop), (\"4-hop\", pools_4hop), (\"5-hop\", pools_5hop)]:\n",
    "    K, M, N = compose_amm_chain(pools)\n",
    "    marginal_rate = K / M\n",
    "    x_opt, profit = optimal_arbitrage_multihop(pools)\n",
    "\n",
    "    # Verify via simulation\n",
    "    actual_output = simulate_multihop(x_opt, pools)\n",
    "    actual_profit = actual_output - x_opt\n",
    "\n",
    "    print(f\"\\n{name} path:\")\n",
    "    print(f\"  K/M (initial marginal rate): {marginal_rate:.6f}\")\n",
    "    print(f\"  x_opt:                       {x_opt:.6f}\")\n",
    "    print(f\"  Analytic profit:             {profit:.6f}\")\n",
    "    print(f\"  Simulated profit:            {actual_profit:.6f}\")\n",
    "    print(f\"  Match:                       {abs(profit - actual_profit) < 1e-10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-bs-header",
   "metadata": {},
   "source": [
    "## Comparison: Closed-Form vs Binary Search (Multi-Hop)\n",
    "\n",
    "We now generalize the binary search from the original analysis to work with arbitrary hop counts. The binary search uses a numerical derivative of the multi-hop profit function, bisecting until convergence. We benchmark it against the Möbius closed-form solution across all path lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-bs-impl",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:43.815399Z",
     "iopub.status.busy": "2026-02-22T05:10:43.815313Z",
     "iopub.status.idle": "2026-02-22T05:10:43.818149Z",
     "shell.execute_reply": "2026-02-22T05:10:43.817726Z"
    }
   },
   "outputs": [],
   "source": [
    "def multihop_profit(x, pools):\n",
    "    \"\"\"Calculate profit for input x through a multi-hop path.\"\"\"\n",
    "    return simulate_multihop(x, pools) - x\n",
    "\n",
    "def binary_search_multihop(pools, precision=1e-12, max_iter=1000):\n",
    "    \"\"\"Find optimal input via binary search on the multi-hop profit derivative.\"\"\"\n",
    "    # Upper bound: minimum input reserve (conservative)\n",
    "    upper = min(r for r, s, f in pools)\n",
    "    left, right = 1e-12, upper\n",
    "    iterations = 0\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        mid = (left + right) / 2\n",
    "        eps = max(abs(mid) * 1e-8, 1e-12)\n",
    "        dp = (multihop_profit(mid + eps, pools) - multihop_profit(mid - eps, pools)) / (2 * eps)\n",
    "\n",
    "        if (right - left) < precision:\n",
    "            break\n",
    "        if dp > 0:\n",
    "            left = mid\n",
    "        else:\n",
    "            right = mid\n",
    "        iterations += 1\n",
    "\n",
    "    return mid, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-benchmark",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:43.819354Z",
     "iopub.status.busy": "2026-02-22T05:10:43.819266Z",
     "iopub.status.idle": "2026-02-22T05:10:43.843850Z",
     "shell.execute_reply": "2026-02-22T05:10:43.843385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path     Method                   x_opt         Profit    Time (us)   Iterations\n",
      "--------------------------------------------------------------------------------\n",
      "2-hop    Binary Search         7.921101       0.015955         41.9           54\n",
      "2-hop    Closed-Form           7.921088       0.015955          0.9            0\n",
      "\n",
      "3-hop    Binary Search        19.078670       1.118604         47.2           50\n",
      "3-hop    Closed-Form          19.078671       1.118604          1.0            0\n",
      "\n",
      "4-hop    Binary Search        85.827103       6.123027         55.9           53\n",
      "4-hop    Closed-Form          85.827103       6.123027          1.1            0\n",
      "\n",
      "5-hop    Binary Search       162.151802      13.873792         64.4           54\n",
      "5-hop    Closed-Form         162.151803      13.873792          1.3            0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Benchmark all path lengths\n",
    "all_pools = [\n",
    "    (\"2-hop\", pools_2hop),\n",
    "    (\"3-hop\", pools_3hop),\n",
    "    (\"4-hop\", pools_4hop),\n",
    "    (\"5-hop\", pools_5hop),\n",
    "]\n",
    "\n",
    "print(f\"{'Path':<8} {'Method':<15} {'x_opt':>14} {'Profit':>14} {'Time (us)':>12} {'Iterations':>12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, pools in all_pools:\n",
    "    # Binary search (average over 100 runs)\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        x_bs, iters = binary_search_multihop(pools)\n",
    "    t_bs = (time.time() - start) / 100\n",
    "    profit_bs = multihop_profit(x_bs, pools)\n",
    "\n",
    "    # Closed-form (average over 100 runs)\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        x_cf, profit_cf = optimal_arbitrage_multihop(pools)\n",
    "    t_cf = (time.time() - start) / 100\n",
    "\n",
    "    print(f\"{name:<8} {'Binary Search':<15} {x_bs:>14.6f} {profit_bs:>14.6f} {t_bs*1e6:>12.1f} {iters:>12}\")\n",
    "    print(f\"{name:<8} {'Closed-Form':<15} {x_cf:>14.6f} {profit_cf:>14.6f} {t_cf*1e6:>12.1f} {'0':>12}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-benchmark-analysis",
   "metadata": {},
   "source": [
    "Both methods converge to the same optimal input and profit for every path length. The closed-form solution requires zero iterations regardless of the number of hops.\n",
    "\n",
    "The time advantage of the closed-form grows with path length: binary search calls the full multi-hop simulation at each iteration (cost per iteration scales linearly with $n$), while the closed-form computes $K$, $M$, $N$ in a single $O(n)$ pass and then evaluates one square root."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-scaling-header",
   "metadata": {},
   "source": [
    "## Scaling: Performance vs Number of Hops\n",
    "\n",
    "The closed-form solution is $O(n)$ for computing $K, M, N$ and $O(1)$ for the final formula. Binary search is $O(n \\cdot I)$ where $I$ is the number of iterations (typically 40-60). Below we measure how both methods scale from 2 to 20 hops using randomly generated paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-scaling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:43.845190Z",
     "iopub.status.busy": "2026-02-22T05:10:43.845102Z",
     "iopub.status.idle": "2026-02-22T05:10:44.169585Z",
     "shell.execute_reply": "2026-02-22T05:10:44.169121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hops   Closed-Form (us)   Binary Search (us)    Speedup\n",
      "----------------------------------------------------------\n",
      "     2                0.9                765.1      858.5x\n",
      "     3                1.0                 50.8       52.6x\n",
      "     4                1.1                 56.1       52.5x\n",
      "     5                1.1                 62.5       56.1x\n",
      "     6                1.2                 68.8       57.5x\n",
      "     7                1.3                 78.0       60.3x\n",
      "     8                1.4                 83.0       59.1x\n",
      "     9                1.5                 89.0       58.7x\n",
      "    10                1.6                 96.4       61.5x\n",
      "    11                1.7                105.0       62.3x\n",
      "    12                1.8                109.4       62.0x\n",
      "    13                1.9                116.4       62.6x\n",
      "    14                1.9                124.9       64.2x\n",
      "    15                2.0                129.1       65.1x\n",
      "    16                2.1                151.2       71.6x\n",
      "    17                2.2                148.0       67.7x\n",
      "    18                2.3                150.9       66.5x\n",
      "    19                2.3                158.3       68.1x\n",
      "    20                2.4                166.2       68.9x\n"
     ]
    }
   ],
   "source": [
    "def generate_random_path(n_hops, k=0.997, seed=42):\n",
    "    \"\"\"Generate a random n-hop circular path with guaranteed arbitrage.\"\"\"\n",
    "    rng = np.random.RandomState(seed + n_hops)\n",
    "    pools = []\n",
    "    for i in range(n_hops):\n",
    "        r_in = rng.uniform(1000, 50000)\n",
    "        s_out = rng.uniform(1000000, 50000000)\n",
    "        pools.append((r_in, s_out, k))\n",
    "\n",
    "    # Ensure arbitrage exists (K/M > 1) by boosting last pool if needed\n",
    "    K, M, N = compose_amm_chain(pools)\n",
    "    if K <= M:\n",
    "        r, s, f = pools[-1]\n",
    "        pools[-1] = (r, s * (M / K) * 1.05, f)  # 5% edge\n",
    "\n",
    "    return pools\n",
    "\n",
    "# Measure scaling from 2 to 20 hops\n",
    "hop_counts = list(range(2, 21))\n",
    "cf_times = []\n",
    "bs_times = []\n",
    "\n",
    "for n in hop_counts:\n",
    "    pools = generate_random_path(n)\n",
    "\n",
    "    # Closed-form timing (average over 1000 runs)\n",
    "    start = time.time()\n",
    "    for _ in range(1000):\n",
    "        optimal_arbitrage_multihop(pools)\n",
    "    cf_times.append((time.time() - start) / 1000 * 1e6)\n",
    "\n",
    "    # Binary search timing (average over 100 runs)\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        binary_search_multihop(pools)\n",
    "    bs_times.append((time.time() - start) / 100 * 1e6)\n",
    "\n",
    "print(f\"{'Hops':>6} {'Closed-Form (us)':>18} {'Binary Search (us)':>20} {'Speedup':>10}\")\n",
    "print(\"-\" * 58)\n",
    "for n, cf, bs in zip(hop_counts, cf_times, bs_times):\n",
    "    print(f\"{n:>6} {cf:>18.1f} {bs:>20.1f} {bs/cf:>10.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-gpu-header",
   "metadata": {},
   "source": [
    "## GPU Batch Analysis: Evaluating Multiple Arbitrage Paths Simultaneously\n",
    "\n",
    "In production MEV systems, the bottleneck is not evaluating a single path — it is scanning **thousands of candidate paths simultaneously** across all available pools. Because our Möbius recurrence operates on simple scalar arithmetic, the entire computation **vectorizes trivially** across a batch of independent paths.\n",
    "\n",
    "Each path is independent — the recurrence for path $i$ reads only from path $i$'s reserves. This is embarrassingly parallel, making it ideal for GPU acceleration.\n",
    "\n",
    "The GPU parallelism works by promoting the three scalars $K$, $M$, $N$ from scalars to **tensors of shape `(batch_size,)`** — one entry per candidate route. The recurrence loop still iterates sequentially over hops (typically 3–5), but each iteration performs a single element-wise operation that updates all routes simultaneously. There is no inner loop over paths; PyTorch broadcasts the arithmetic across the entire batch in one vectorized call per hop. This is the mechanism of parallelism: not literal $2\\times2$ matrix multiplications, but vectorized scalar recurrence over the batch dimension.\n",
    "\n",
    "Using PyTorch, we evaluate 100,000+ candidate arbitrage routes on GPU. On Apple Silicon Macs, the MPS (Metal Performance Shaders) backend provides native GPU acceleration. GPU wins at ≥100K routes — below that threshold, MPS dispatch and sync overhead swamps the compute, and CPU is actually faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-torch-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:44.170976Z",
     "iopub.status.busy": "2026-02-22T05:10:44.170845Z",
     "iopub.status.idle": "2026-02-22T05:10:45.136604Z",
     "shell.execute_reply": "2026-02-22T05:10:45.136183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 2.10.0\n",
      "GPU: MPS (Apple GPU)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "    MPS_AVAILABLE = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()\n",
    "    CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "    if MPS_AVAILABLE:\n",
    "        GPU_DEVICE = torch.device('mps')\n",
    "        GPU_NAME = \"MPS (Apple GPU)\"\n",
    "    elif CUDA_AVAILABLE:\n",
    "        GPU_DEVICE = torch.device('cuda')\n",
    "        GPU_NAME = f\"CUDA ({torch.cuda.get_device_name(0)})\"\n",
    "    else:\n",
    "        GPU_DEVICE = None\n",
    "        GPU_NAME = \"No GPU available (CPU-only benchmarks below)\"\n",
    "\n",
    "    print(f\"PyTorch {torch.__version__}\")\n",
    "    print(f\"GPU: {GPU_NAME}\")\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    MPS_AVAILABLE = False\n",
    "    CUDA_AVAILABLE = False\n",
    "    GPU_DEVICE = None\n",
    "    print(\"PyTorch not installed. Install with: pip install torch\")\n",
    "    print(\"GPU benchmarks will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-batched-impl",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:45.138015Z",
     "iopub.status.busy": "2026-02-22T05:10:45.137919Z",
     "iopub.status.idle": "2026-02-22T05:10:45.142182Z",
     "shell.execute_reply": "2026-02-22T05:10:45.141669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched GPU functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    def compose_amm_chain_batched(pools_tensor):\n",
    "        \"\"\"\n",
    "        Compute K, M, N for a batch of multi-hop paths.\n",
    "\n",
    "        Parameters:\n",
    "            pools_tensor: shape (batch_size, n_hops, 3)\n",
    "                          where dim 2 = [r_in, s_out, fee_factor]\n",
    "\n",
    "        Returns:\n",
    "            K, M, N each of shape (batch_size,)\n",
    "        \"\"\"\n",
    "        batch, n_hops, _ = pools_tensor.shape\n",
    "\n",
    "        # First hop\n",
    "        r = pools_tensor[:, 0, 0]\n",
    "        s = pools_tensor[:, 0, 1]\n",
    "        f = pools_tensor[:, 0, 2]\n",
    "        K = s * f\n",
    "        M = r.clone()\n",
    "        N = f.clone()\n",
    "\n",
    "        # Remaining hops (fully vectorized over batch dimension)\n",
    "        for i in range(1, n_hops):\n",
    "            r = pools_tensor[:, i, 0]\n",
    "            s = pools_tensor[:, i, 1]\n",
    "            f = pools_tensor[:, i, 2]\n",
    "            K_new = s * f * K\n",
    "            M_new = r * M\n",
    "            N_new = r * N + f * K  # uses old K\n",
    "            K, M, N = K_new, M_new, N_new\n",
    "\n",
    "        return K, M, N\n",
    "\n",
    "\n",
    "    def optimal_arbitrage_batched(pools_tensor):\n",
    "        \"\"\"\n",
    "        Compute optimal input for a batch of multi-hop paths.\n",
    "\n",
    "        Parameters:\n",
    "            pools_tensor: shape (batch_size, n_hops, 3)\n",
    "\n",
    "        Returns:\n",
    "            x_opt: shape (batch_size,) -- optimal inputs (0 where no arb)\n",
    "            profit: shape (batch_size,) -- expected profits\n",
    "        \"\"\"\n",
    "        K, M, N = compose_amm_chain_batched(pools_tensor)\n",
    "\n",
    "        sqrt_km = torch.sqrt(K * M)\n",
    "        x_opt = (sqrt_km - M) / N\n",
    "\n",
    "        # Compute profit\n",
    "        l_x = K * x_opt / (M + N * x_opt)\n",
    "        profit = l_x - x_opt\n",
    "\n",
    "        # Zero out cases with no profitable arbitrage\n",
    "        no_arb = (K <= M) | (x_opt <= 0)\n",
    "        x_opt = torch.where(no_arb, torch.zeros_like(x_opt), x_opt)\n",
    "        profit = torch.where(no_arb, torch.zeros_like(profit), profit)\n",
    "\n",
    "        return x_opt, profit\n",
    "\n",
    "    print(\"Batched GPU functions defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-gpu-benchmark",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:45.143382Z",
     "iopub.status.busy": "2026-02-22T05:10:45.143288Z",
     "iopub.status.idle": "2026-02-22T05:10:47.646021Z",
     "shell.execute_reply": "2026-02-22T05:10:47.645403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch Size     CPU (us)     GPU (us)    Speedup\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          10         60.2        573.1       0.1x\n",
      "         100         64.1        626.1       0.1x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1000         93.7        728.8       0.1x\n",
      "       10000        353.2        825.3       0.4x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      100000       2714.8       2049.9       1.3x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1000000      58615.4      18498.0       3.2x\n"
     ]
    }
   ],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    def generate_batch_data(batch_size, n_hops, k=0.997, device='cpu', dtype=None):\n",
    "        \"\"\"Generate a batch of random multi-hop paths as a tensor.\n",
    "\n",
    "        Defaults to float64 on CPU for numerical stability (float32 overflows at\n",
    "        5 hops with s_out up to 50M). MPS doesn't support float64, so GPU runs\n",
    "        use float32; the timing benchmark remains valid even if values hit inf.\n",
    "        \"\"\"\n",
    "        if dtype is None:\n",
    "            dev = device if isinstance(device, torch.device) else torch.device(device)\n",
    "            dtype = torch.float32 if dev.type == 'mps' else torch.float64\n",
    "        r_in = torch.rand(batch_size, n_hops, 1, device=device, dtype=dtype) * 49000 + 1000\n",
    "        s_out = torch.rand(batch_size, n_hops, 1, device=device, dtype=dtype) * 49000000 + 1000000\n",
    "        fees = torch.full((batch_size, n_hops, 1), k, device=device, dtype=dtype)\n",
    "        return torch.cat([r_in, s_out, fees], dim=2)\n",
    "\n",
    "    # Benchmark parameters\n",
    "    batch_sizes = [10, 100, 1_000, 10_000, 100_000, 1_000_000]\n",
    "    n_hops = 5\n",
    "    n_warmup = 10\n",
    "    n_runs_map = {10: 200, 100: 200, 1_000: 100, 10_000: 50, 100_000: 20, 1_000_000: 5}\n",
    "\n",
    "    # Print header\n",
    "    header = f\"{'Batch Size':>12} {'CPU (us)':>12}\"\n",
    "    if GPU_DEVICE is not None:\n",
    "        header += f\" {'GPU (us)':>12} {'Speedup':>10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        n_runs = n_runs_map[batch_size]\n",
    "\n",
    "        # ---- CPU benchmark ----\n",
    "        pools_cpu = generate_batch_data(batch_size, n_hops, device='cpu')\n",
    "\n",
    "        for _ in range(n_warmup):\n",
    "            optimal_arbitrage_batched(pools_cpu)\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(n_runs):\n",
    "            optimal_arbitrage_batched(pools_cpu)\n",
    "        cpu_time = (time.time() - start) / n_runs * 1e6\n",
    "\n",
    "        row = f\"{batch_size:>12} {cpu_time:>12.1f}\"\n",
    "\n",
    "        # ---- GPU benchmark ----\n",
    "        if GPU_DEVICE is not None:\n",
    "            pools_gpu = generate_batch_data(batch_size, n_hops, device=GPU_DEVICE)\n",
    "\n",
    "            # Warmup (critical for GPU)\n",
    "            for _ in range(n_warmup):\n",
    "                x, p = optimal_arbitrage_batched(pools_gpu)\n",
    "                if MPS_AVAILABLE:\n",
    "                    torch.mps.synchronize()\n",
    "                elif CUDA_AVAILABLE:\n",
    "                    torch.cuda.synchronize()\n",
    "\n",
    "            start = time.time()\n",
    "            for _ in range(n_runs):\n",
    "                x, p = optimal_arbitrage_batched(pools_gpu)\n",
    "                if MPS_AVAILABLE:\n",
    "                    torch.mps.synchronize()\n",
    "                elif CUDA_AVAILABLE:\n",
    "                    torch.cuda.synchronize()\n",
    "            gpu_time = (time.time() - start) / n_runs * 1e6\n",
    "\n",
    "            row += f\" {gpu_time:>12.1f} {cpu_time/gpu_time:>9.1f}x\"\n",
    "\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-sample-results",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T05:10:47.647493Z",
     "iopub.status.busy": "2026-02-22T05:10:47.647340Z",
     "iopub.status.idle": "2026-02-22T05:10:47.665409Z",
     "shell.execute_reply": "2026-02-22T05:10:47.664972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 10 simultaneous 5-hop arbitrage evaluations\n",
      "  Path          x_opt         Profit   Profitable\n",
      "--------------------------------------------------\n",
      "     1         0.0430  25436189.5291          Yes\n",
      "     2         0.2844  14545446.0972          Yes\n",
      "     3         2.1618  18328832.4994          Yes\n",
      "     4         0.1764   8072398.2011          Yes\n",
      "     5         0.1953  32528241.8987          Yes\n",
      "     6         0.4498  15676387.3643          Yes\n",
      "     7         0.4178  44546959.4982          Yes\n",
      "     8         0.4423   5632207.3716          Yes\n",
      "     9         1.0556  47007176.3256          Yes\n",
      "    10         2.1371  47753978.2429          Yes\n",
      "\n",
      "10/10 paths have profitable arbitrage opportunities\n"
     ]
    }
   ],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    # Show sample results for 10 simultaneous 5-hop arbitrage evaluations\n",
    "    torch.manual_seed(42)\n",
    "    pools_sample = generate_batch_data(10, 5, device='cpu')\n",
    "    x_opts, profits = optimal_arbitrage_batched(pools_sample)\n",
    "\n",
    "    print(f\"Sample: 10 simultaneous {n_hops}-hop arbitrage evaluations\")\n",
    "    print(f\"{'Path':>6} {'x_opt':>14} {'Profit':>14} {'Profitable':>12}\")\n",
    "    print(\"-\" * 50)\n",
    "    for i in range(10):\n",
    "        arb = \"Yes\" if profits[i] > 0 else \"No\"\n",
    "        print(f\"{i+1:>6} {x_opts[i].item():>14.4f} {profits[i].item():>14.4f} {arb:>12}\")\n",
    "\n",
    "    n_profitable = (profits > 0).sum().item()\n",
    "    print(f\"\\n{n_profitable}/10 paths have profitable arbitrage opportunities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Möbius transformation framework provides a complete generalization of the single-hop closed-form arbitrage formula to paths of arbitrary length:\n",
    "\n",
    "1. **Each hop** is a Möbius transformation representable as a $2 \\times 2$ matrix: $\\mathbf{M}_i = \\begin{pmatrix} s_i f_i & 0 \\\\ f_i & r_i \\end{pmatrix}$\n",
    "\n",
    "2. **The full path** composes via matrix multiplication or, equivalently, a 3-number recurrence on $K$, $M$, $N$\n",
    "\n",
    "3. **The output** always has the form $l(x) = \\frac{Kx}{M + Nx}$, regardless of hop count\n",
    "\n",
    "4. **The optimal input** is $x_{\\text{opt}} = \\frac{\\sqrt{KM} - M}{N}$\n",
    "\n",
    "5. **The computation vectorizes** trivially across thousands of candidate paths for GPU-accelerated batch scanning\n",
    "\n",
    "This extends the original $O(1)$ single-hop formula to an $O(n)$ multi-hop formula where $n$ is the number of pools in the path. The closed-form matches binary search results exactly while eliminating all iteration, approximation error, and convergence tuning. Because the recurrence is pure arithmetic on three scalars, it maps naturally to GPU hardware — enabling real-time scanning of massive route spaces in production MEV systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_physics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
